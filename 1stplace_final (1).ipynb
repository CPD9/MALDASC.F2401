{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304d9dc2-83a8-426e-b252-6cc437682b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q kaggle\n",
    "# !mkdir -p ./kaggle\n",
    "# !cp kaggle.json ./kaggle/\n",
    "# !chmod 600 ./kaggle/kaggle.json\n",
    "# !cat ./kaggle/kaggle.json\n",
    "# ! kaggle datasets list\n",
    "# !kaggle datasets download -d haqishen/timm-20220211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12eb849d-02b9-4c7d-a019-14c47354ee2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./seg_model.zip\n",
      "  inflating: ./seg_model/timm3d_v2s_unet4b_128_128_128_dsv2_flip12_shift333p7_gd1p5_mixup1_lr1e3_20x50ep_fold0_best.pth  \n",
      "  inflating: ./seg_model/timm3d_v2s_unet4b_128_128_128_dsv2_flip12_shift333p7_gd1p5_mixup1_lr1e3_20x50ep_fold1_best.pth  \n",
      "  inflating: ./seg_model/timm3d_v2s_unet4b_128_128_128_dsv2_flip12_shift333p7_gd1p5_mixup1_lr1e3_20x50ep_fold2_best.pth  \n",
      "  inflating: ./seg_model/timm3d_v2s_unet4b_128_128_128_dsv2_flip12_shift333p7_gd1p5_mixup1_lr1e3_20x50ep_fold3_best.pth  \n",
      "  inflating: ./seg_model/timm3d_v2s_unet4b_128_128_128_dsv2_flip12_shift333p7_gd1p5_mixup1_lr1e3_20x50ep_fold4_best.pth  \n"
     ]
    }
   ],
   "source": [
    "!unzip ./seg_model.zip -d ./seg_model\n",
    "#!cp -r ./timm-20220211/pytorch-image-models-master/timm/Â ./timm4smp\n",
    "#!cp -r ./timm-20220211/pytorch-image-models-master/timm/ ./timm4smp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb8edf6d-2799-447e-98fa-bdc1ddbb218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# # Specify the directory you want to delete\n",
    "directory_to_delete = './seg_model'\n",
    "\n",
    "\n",
    "# # Delete the directory and all its contents\n",
    "shutil.rmtree(directory_to_delete)\n",
    "\n",
    "#print(\"Directory deleted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d469b59-c4d2-4e5d-b5f8-c7ab319e01ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /opt/conda/lib/python3.11/site-packages (0.9.16)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from timm) (2.3.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from timm) (0.18.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (from timm) (0.23.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from timm) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (3.12.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (2023.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (23.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->timm) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.4.127)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision->timm) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Collecting albumentations\n",
      "  Obtaining dependency information for albumentations from https://files.pythonhosted.org/packages/d3/23/70ea1667f96586fb21645a70b880703586a6133e6e3c0bcf7cf06499b594/albumentations-1.4.6-py3-none-any.whl.metadata\n",
      "  Using cached albumentations-1.4.6-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.11/site-packages (from albumentations) (1.26.4)\n",
      "Collecting scipy>=1.10.0 (from albumentations)\n",
      "  Obtaining dependency information for scipy>=1.10.0 from https://files.pythonhosted.org/packages/e8/fb/e5955e2ddbdf2baee461eb53ec8d0adedd20a6dfc5510ef8d5e7e44ba461/scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting scikit-image>=0.21.0 (from albumentations)\n",
      "  Obtaining dependency information for scikit-image>=0.21.0 from https://files.pythonhosted.org/packages/0a/40/2c57864acd77c168b96cb6e4e62651b9c98733962793293991ef55e2982c/scikit_image-0.23.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scikit_image-0.23.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.11/site-packages (from albumentations) (6.0.1)\n",
      "Collecting typing-extensions>=4.9.0 (from albumentations)\n",
      "  Obtaining dependency information for typing-extensions>=4.9.0 from https://files.pythonhosted.org/packages/01/f3/936e209267d6ef7510322191003885de524fc48d1b43269810cd589ceaf5/typing_extensions-4.11.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting scikit-learn>=1.3.2 (from albumentations)\n",
      "  Obtaining dependency information for scikit-learn>=1.3.2 from https://files.pythonhosted.org/packages/4e/53/14405a47292b59235d811a2af8634aba188ccfd1a38ef4b8042f3447d79a/scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pydantic>=2.7.0 (from albumentations)\n",
      "  Obtaining dependency information for pydantic>=2.7.0 from https://files.pythonhosted.org/packages/ed/76/9a17032880ed27f2dbd490c77a3431cbc80f47ba81534131de3c2846e736/pydantic-2.7.1-py3-none-any.whl.metadata\n",
      "  Using cached pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0 in /opt/conda/lib/python3.11/site-packages (from albumentations) (4.9.0.80)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.7.0->albumentations)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic>=2.7.0->albumentations)\n",
      "  Obtaining dependency information for pydantic-core==2.18.2 from https://files.pythonhosted.org/packages/80/b8/b93d756b36425f7ad378dcb9fdf5f6a03b88afaae0476f7bdb31dd8964be/pydantic_core-2.18.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached pydantic_core-2.18.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (3.1)\n",
      "Requirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (10.3.0)\n",
      "Collecting imageio>=2.33 (from scikit-image>=0.21.0->albumentations)\n",
      "  Obtaining dependency information for imageio>=2.33 from https://files.pythonhosted.org/packages/a3/b6/39c7dad203d9984225f47e0aa39ac3ba3a47c77a02d0ef2a7be691855a06/imageio-2.34.1-py3-none-any.whl.metadata\n",
      "  Using cached imageio-2.34.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image>=0.21.0->albumentations)\n",
      "  Obtaining dependency information for tifffile>=2022.8.12 from https://files.pythonhosted.org/packages/c1/79/29d0fa40017f7b749ce344759dcc21e2ec9bbb81fc69ca2ce06e261f83f0/tifffile-2024.5.10-py3-none-any.whl.metadata\n",
      "  Downloading tifffile-2024.5.10-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (23.1)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image>=0.21.0->albumentations)\n",
      "  Obtaining dependency information for lazy-loader>=0.4 from https://files.pythonhosted.org/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl.metadata\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.3.2->albumentations)\n",
      "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=1.3.2->albumentations)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl.metadata\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached albumentations-1.4.6-py3-none-any.whl (153 kB)\n",
      "Using cached pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "Using cached pydantic_core-2.18.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached scikit_image-0.23.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "Using cached scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Using cached scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached imageio-2.34.1-py3-none-any.whl (313 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tifffile-2024.5.10-py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-extensions, tifffile, threadpoolctl, scipy, lazy-loader, joblib, imageio, annotated-types, scikit-learn, scikit-image, pydantic-core, pydantic, albumentations\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "Successfully installed albumentations-1.4.6 annotated-types-0.6.0 imageio-2.34.1 joblib-1.4.2 lazy-loader-0.4 pydantic-2.7.1 pydantic-core-2.18.2 scikit-image-0.23.2 scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.5.0 tifffile-2024.5.10 typing-extensions-4.11.0\n",
      "Collecting segmentation_models_pytorch\n",
      "  Obtaining dependency information for segmentation_models_pytorch from https://files.pythonhosted.org/packages/cb/70/4aac1b240b399b108ce58029ae54bc14497e1bbc275dfab8fd3c84c1e35d/segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata\n",
      "  Using cached segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (0.18.0)\n",
      "Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n",
      "  Using cached pretrainedmodels-0.7.4-py3-none-any.whl\n",
      "Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n",
      "  Using cached efficientnet_pytorch-0.7.1-py3-none-any.whl\n",
      "Collecting timm==0.9.2 (from segmentation_models_pytorch)\n",
      "  Obtaining dependency information for timm==0.9.2 from https://files.pythonhosted.org/packages/29/90/94f5deb8d76e24a89813aef95e8809ca8fd7414490428480eda19b133d4a/timm-0.9.2-py3-none-any.whl.metadata\n",
      "  Using cached timm-0.9.2-py3-none-any.whl.metadata (68 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (4.66.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (10.3.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.0)\n",
      "Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n",
      "  Obtaining dependency information for munch from https://files.pythonhosted.org/packages/56/b3/7c69b37f03260a061883bec0e7b05be7117c1b1c85f5212c72c8c2bc3c8c/munch-4.0.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.11/site-packages (from timm==0.9.2->segmentation_models_pytorch) (0.23.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.4.127)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (23.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n",
      "Using cached segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
      "Using cached timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
      "Using cached munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n",
      "  Attempting uninstall: timm\n",
      "    Found existing installation: timm 0.9.16\n",
      "    Uninstalling timm-0.9.16:\n",
      "      Successfully uninstalled timm-0.9.16\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3 timm-0.9.2\n",
      "Collecting monai\n",
      "  Obtaining dependency information for monai from https://files.pythonhosted.org/packages/08/94/e8a7ba00dd0c7ce959648b562043bd22125d65f5e519e566c822f71bc437/monai-1.3.0-202310121228-py3-none-any.whl.metadata\n",
      "  Using cached monai-1.3.0-202310121228-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.11/site-packages (from monai) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.11/site-packages (from monai) (2.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.9->monai) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->monai) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
      "Using cached monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\n",
      "Installing collected packages: monai\n",
      "Successfully installed monai-1.3.0\n",
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.11/site-packages (2.34.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from imageio) (1.26.4)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.11/site-packages (from imageio) (10.3.0)\n",
      "Collecting pydicom\n",
      "  Obtaining dependency information for pydicom from https://files.pythonhosted.org/packages/35/2a/8c0f6fe243e6b6793868c6834203a44cc8f3f25abad780e1c7b21e15594d/pydicom-2.4.4-py3-none-any.whl.metadata\n",
      "  Using cached pydicom-2.4.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Using cached pydicom-2.4.4-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pydicom\n",
      "Successfully installed pydicom-2.4.4\n",
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/fc/a5/4d82be566f069d7a9a702dcdf6f9106df0e0b042e738043c0cc7ddd7e3f6/pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-2.2.2\n",
      "Collecting nibabel\n",
      "  Obtaining dependency information for nibabel from https://files.pythonhosted.org/packages/77/3f/ce43b8c2ccc4a7913a87c4d425aaf0080ea3abf947587e47dc2025981a17/nibabel-5.2.1-py3-none-any.whl.metadata\n",
      "  Using cached nibabel-5.2.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.11/site-packages (from nibabel) (1.26.4)\n",
      "Requirement already satisfied: packaging>=17 in /opt/conda/lib/python3.11/site-packages (from nibabel) (23.1)\n",
      "Using cached nibabel-5.2.1-py3-none-any.whl (3.3 MB)\n",
      "Installing collected packages: nibabel\n",
      "Successfully installed nibabel-5.2.1\n",
      "Collecting matplotlib\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/80/3b/e363612ac1a514abfb5505aa209dd5b724b3232a6de98710d7759559706a/matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/ee/c0/9bd123d676eb61750e116a2cd915b06483fc406143cfc36c7f263f0f5368/contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/c6/b5/dc17e93f60567fa1b0fa3720c2f28e0df5293927e2356e066e87af9adaba/fonttools-4.51.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached fonttools-4.51.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Obtaining dependency information for kiwisolver>=1.3.1 from https://files.pythonhosted.org/packages/17/ba/17a706b232308e65f57deeccae503c268292e6a091313f6ce833a23093ea/kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Using cached matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Using cached contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (306 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.51.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "Using cached kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.51.0 kiwisolver-1.4.5 matplotlib-3.8.4\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.11/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.11/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.11/site-packages (from opencv-python-headless) (1.26.4)\n",
      "Collecting pylibjpeg==1.4.0\n",
      "  Obtaining dependency information for pylibjpeg==1.4.0 from https://files.pythonhosted.org/packages/71/54/c9a15a05027316973686b5e6c5c6c306feb989810123928446f0ec588c2c/pylibjpeg-1.4.0-py3-none-any.whl.metadata\n",
      "  Using cached pylibjpeg-1.4.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from pylibjpeg==1.4.0) (1.26.4)\n",
      "Using cached pylibjpeg-1.4.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: pylibjpeg\n",
      "Successfully installed pylibjpeg-1.4.0\n",
      "Collecting python_gdcm==3.0.17.1\n",
      "  Obtaining dependency information for python_gdcm==3.0.17.1 from https://files.pythonhosted.org/packages/ef/c0/c8a270b85790c4af0445d9e249d39e5a5910cfa527117b9246e9647aa4e3/python_gdcm-3.0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached python_gdcm-3.0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Using cached python_gdcm-3.0.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "Installing collected packages: python_gdcm\n",
      "Successfully installed python_gdcm-3.0.17.1\n",
      "Collecting pylibjpeg-libjpeg\n",
      "  Obtaining dependency information for pylibjpeg-libjpeg from https://files.pythonhosted.org/packages/3b/4a/8debd5c101f4e590c13d9a9f7e6ba9d63e01acdd0fef126fe9f3737b72ed/pylibjpeg_libjpeg-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached pylibjpeg_libjpeg-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.24 in /opt/conda/lib/python3.11/site-packages (from pylibjpeg-libjpeg) (1.26.4)\n",
      "Using cached pylibjpeg_libjpeg-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "Installing collected packages: pylibjpeg-libjpeg\n",
      "Successfully installed pylibjpeg-libjpeg-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install timm\n",
    "!pip install albumentations\n",
    "!pip install segmentation_models_pytorch\n",
    "!pip install monai\n",
    "!pip install imageio\n",
    "!pip install pydicom\n",
    "!pip install pandas\n",
    "!pip install nibabel\n",
    "!pip install matplotlib\n",
    "!pip install torch\n",
    "!pip install opencv-python\n",
    "!pip install opencv-python-headless\n",
    "!pip install pylibjpeg==1.4.0\n",
    "!pip install python_gdcm==3.0.17.1\n",
    "!pip install pylibjpeg-libjpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d853972-3b8b-44f6-bfb6-7eac38e4cb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.9.16', '0.5.5')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import cv2\n",
    "import time\n",
    "import timm\n",
    "import timm4smp\n",
    "import pickle\n",
    "import random\n",
    "import pydicom\n",
    "import argparse\n",
    "import warnings\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "device = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "timm.__version__, timm4smp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd7d76-bc21-4742-ae87-d5f990c29a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "753f139a-4c6d-49c9-9e2e-c634bac4f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './Dataset'\n",
    "image_size_seg = (128, 128, 128)\n",
    "msk_size = image_size_seg[0]\n",
    "image_size_cls = 224\n",
    "n_slice_per_c = 15\n",
    "n_ch = 5\n",
    "\n",
    "batch_size_seg = 1\n",
    "num_workers = 2\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb8d231e-4af2-4fc3-a714-ae09207acd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>prediction_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.10197_C1</td>\n",
       "      <td>1.2.826.0.1.3680043.10197</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.10454_C1</td>\n",
       "      <td>1.2.826.0.1.3680043.10454</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.10690_C1</td>\n",
       "      <td>1.2.826.0.1.3680043.10690</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         row_id           StudyInstanceUID prediction_type\n",
       "0  1.2.826.0.1.3680043.10197_C1  1.2.826.0.1.3680043.10197              C1\n",
       "1  1.2.826.0.1.3680043.10454_C1  1.2.826.0.1.3680043.10454              C1\n",
       "2  1.2.826.0.1.3680043.10690_C1  1.2.826.0.1.3680043.10690              C1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./Dataset/test.csv\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afe1b775-07b3-4438-8493-40b3ba746756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>image_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>./Dataset/test_images/1.2.826.0.1.3680043.22327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.25399</td>\n",
       "      <td>./Dataset/test_images/1.2.826.0.1.3680043.25399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>./Dataset/test_images/1.2.826.0.1.3680043.5876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID                                     image_folder\n",
       "0  1.2.826.0.1.3680043.22327  ./Dataset/test_images/1.2.826.0.1.3680043.22327\n",
       "1  1.2.826.0.1.3680043.25399  ./Dataset/test_images/1.2.826.0.1.3680043.25399\n",
       "2   1.2.826.0.1.3680043.5876   ./Dataset/test_images/1.2.826.0.1.3680043.5876"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    df = pd.read_csv(os.path.join(data_dir, 'train.csv')).head(1500)\n",
    "    df = pd.DataFrame({\n",
    "        'StudyInstanceUID': df['StudyInstanceUID'].unique().tolist()\n",
    "    })\n",
    "    df['image_folder'] = df['StudyInstanceUID'].apply(lambda x: os.path.join(data_dir, 'train_images', x))\n",
    "else:\n",
    "    df = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "    if df.iloc[0].row_id == '1.2.826.0.1.3680043.10197_C1':\n",
    "        # test_images and test.csv are inconsistent in the dev dataset, fixing labels for the dev run.\n",
    "        df = pd.DataFrame({\n",
    "            \"row_id\": ['1.2.826.0.1.3680043.22327_C1', '1.2.826.0.1.3680043.25399_C1', '1.2.826.0.1.3680043.5876_C1'],\n",
    "            \"StudyInstanceUID\": ['1.2.826.0.1.3680043.22327', '1.2.826.0.1.3680043.25399', '1.2.826.0.1.3680043.5876'],\n",
    "            \"prediction_type\": [\"C1\", \"C1\", \"patient_overall\"]}\n",
    "        )\n",
    "    df = pd.DataFrame({\n",
    "        'StudyInstanceUID': df['StudyInstanceUID'].unique().tolist()\n",
    "    })\n",
    "    df['image_folder'] = df['StudyInstanceUID'].apply(lambda x: os.path.join(data_dir, 'test_images', x))\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad507dc-b8ef-4070-bd2b-28f6c2cdf20c",
   "metadata": {},
   "source": [
    "<h2>Dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5a1f1ab-14ef-4044-b510-75b970ceac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom(path):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    data = cv2.resize(data, (image_size_seg[0], image_size_seg[1]), interpolation = cv2.INTER_AREA)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_dicom_line_par(path):\n",
    "\n",
    "    t_paths = sorted(glob(os.path.join(path, \"*\")), key=lambda x: int(x.split('/')[-1].split(\".\")[0]))\n",
    "\n",
    "    n_scans = len(t_paths)\n",
    "#     print(n_scans)\n",
    "    indices = np.quantile(list(range(n_scans)), np.linspace(0., 1., image_size_seg[2])).round().astype(int)\n",
    "    t_paths = [t_paths[i] for i in indices]\n",
    "\n",
    "    images = []\n",
    "    for filename in t_paths:\n",
    "        images.append(load_dicom(filename))\n",
    "    images = np.stack(images, -1)\n",
    "    \n",
    "    images = images - np.min(images)\n",
    "    images = images / (np.max(images) + 1e-4)\n",
    "    images = (images * 255).astype(np.uint8)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "class SegTestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        image = load_dicom_line_par(row.image_folder)\n",
    "        if image.ndim < 4:\n",
    "            image = np.expand_dims(image, 0)\n",
    "        image = image.astype(np.float32).repeat(3, 0)  # to 3ch\n",
    "        image = image / 255.\n",
    "        return torch.tensor(image).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd432f2a-a490-4610-aa9f-79be81027800",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_seg = SegTestDataset(df)\n",
    "loader_seg = torch.utils.data.DataLoader(dataset_seg, batch_size=batch_size_seg, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80649d42-5649-4208-819c-196348bc871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    rcParams['figure.figsize'] = 20,8\n",
    "    for i in range(2):\n",
    "        f, axarr = plt.subplots(1,4)\n",
    "        for p in range(4):\n",
    "            idx = i*4+p\n",
    "            img = dataset_seg[idx]\n",
    "            img = img[:, :, :, 60]\n",
    "            axarr[p].imshow(img.transpose(0, 1).transpose(1,2).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "125ffcfa-757d-4769-8a85-56adbca5886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    rcParams['figure.figsize'] = 20,8\n",
    "    for i in range(2):\n",
    "        f, axarr = plt.subplots(1,4)\n",
    "        for p in range(4):\n",
    "            idx = i*4+p\n",
    "            img = dataset_seg[idx]\n",
    "            img = img[:, :, 60, :]\n",
    "            axarr[p].imshow(img.transpose(0, 1).transpose(1,2).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e18e651-83b7-4e7a-8c2b-18688915b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    rcParams['figure.figsize'] = 20,8\n",
    "    for i in range(2):\n",
    "        f, axarr = plt.subplots(1,4)\n",
    "        for p in range(4):\n",
    "            idx = i*4+p\n",
    "            img = dataset_seg[idx]\n",
    "            img = img[:, 60, :, :]\n",
    "            axarr[p].imshow(img.transpose(0, 1).transpose(1,2).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d890662-7ddb-4b79-9a68-5c50000f79bd",
   "metadata": {},
   "source": [
    "<h2>Models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1877f514-c0fe-4cb4-bca3-8480a94f156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Conv3d w/ Same Padding\n",
    "modified from:\n",
    "https://github.com/rwightman/pytorch-image-models/blob/a2727c1bf78ba0d7b5727f5f95e37fb7f8866b1f/timm/models/layers/conv2d_same.py\n",
    "https://github.com/rwightman/pytorch-image-models/blob/a2727c1bf78ba0d7b5727f5f95e37fb7f8866b1f/timm/models/layers/padding.py\n",
    "\"\"\"\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple, Optional, List\n",
    "\n",
    "\n",
    "# Calculate symmetric padding for a convolution\n",
    "def get_padding(kernel_size: int, stride: int = 1, dilation: int = 1, **_) -> int:\n",
    "    padding = ((stride - 1) + dilation * (kernel_size - 1)) // 2\n",
    "    return padding\n",
    "\n",
    "\n",
    "# Calculate asymmetric TensorFlow-like 'SAME' padding for a convolution\n",
    "def get_same_padding(x: int, k: int, s: int, d: int):\n",
    "    return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
    "\n",
    "\n",
    "# Can SAME padding for given args be done statically?\n",
    "def is_static_pad(kernel_size: int, stride: int = 1, dilation: int = 1, **_):\n",
    "    return stride == 1 and (dilation * (kernel_size - 1)) % 2 == 0\n",
    "\n",
    "\n",
    "# Dynamically pad input x with 'SAME' padding for conv with specified args\n",
    "def pad_same(x, k: List[int], s: List[int], d: List[int] = (1, 1, 1), value: float = 0):\n",
    "    ih, iw, iz = x.size()[-3:]\n",
    "    pad_h = get_same_padding(ih, k[0], s[0], d[0])\n",
    "    pad_w = get_same_padding(iw, k[1], s[1], d[1])\n",
    "    pad_z = get_same_padding(iz, k[2], s[2], d[2])\n",
    "    if pad_h > 0 or pad_w > 0 or pad_z > 0:\n",
    "        x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2, pad_z // 2, pad_z - pad_z // 2], value=value)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_padding_value(padding, kernel_size, **kwargs) -> Tuple[Tuple, bool]:\n",
    "    dynamic = False\n",
    "    if isinstance(padding, str):\n",
    "        # for any string padding, the padding will be calculated for you, one of three ways\n",
    "        padding = padding.lower()\n",
    "        if padding == 'same':\n",
    "            # TF compatible 'SAME' padding, has a performance and GPU memory allocation impact\n",
    "            if is_static_pad(kernel_size, **kwargs):\n",
    "                # static case, no extra overhead\n",
    "                padding = get_padding(kernel_size, **kwargs)\n",
    "            else:\n",
    "                # dynamic 'SAME' padding, has runtime/GPU memory overhead\n",
    "                padding = 0\n",
    "                dynamic = True\n",
    "        elif padding == 'valid':\n",
    "            # 'VALID' padding, same as padding=0\n",
    "            padding = 0\n",
    "        else:\n",
    "            # Default to PyTorch style 'same'-ish symmetric padding\n",
    "            padding = get_padding(kernel_size, **kwargs)\n",
    "    return padding, dynamic\n",
    "\n",
    "\n",
    "def conv3d_same(\n",
    "        x, weight: torch.Tensor, bias: Optional[torch.Tensor] = None, stride: Tuple[int, int, int] = (1, 1, 1),\n",
    "        padding: Tuple[int, int, int] = (0, 0, 0), dilation: Tuple[int, int, int] = (1, 1, 1), groups: int = 1):\n",
    "    x = pad_same(x, weight.shape[-3:], stride, dilation)\n",
    "    return F.conv3d(x, weight, bias, stride, (0, 0, 0), dilation, groups)\n",
    "\n",
    "\n",
    "class Conv3dSame(nn.Conv3d):\n",
    "    \"\"\" Tensorflow like 'SAME' convolution wrapper for 3d convolutions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(Conv3dSame, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return conv3d_same(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "\n",
    "def create_conv3d_pad(in_chs, out_chs, kernel_size, **kwargs):\n",
    "    padding = kwargs.pop('padding', '')\n",
    "    kwargs.setdefault('bias', False)\n",
    "    padding, is_dynamic = get_padding_value(padding, kernel_size, **kwargs)\n",
    "    if is_dynamic:\n",
    "        return Conv3dSame(in_chs, out_chs, kernel_size, **kwargs)\n",
    "    else:\n",
    "        return nn.Conv3d(in_chs, out_chs, kernel_size, padding=padding, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11125ffd-e4e2-4a87-9a80-06bcc75967d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm4smp.models.layers.conv2d_same import Conv2dSame\n",
    "from timm4smp.models import create_model\n",
    "\n",
    "def convert_3d(module):\n",
    "\n",
    "    module_output = module\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module_output = torch.nn.BatchNorm3d(\n",
    "            module.num_features,\n",
    "            module.eps,\n",
    "            module.momentum,\n",
    "            module.affine,\n",
    "            module.track_running_stats,\n",
    "        )\n",
    "        if module.affine:\n",
    "            with torch.no_grad():\n",
    "                module_output.weight = module.weight\n",
    "                module_output.bias = module.bias\n",
    "        module_output.running_mean = module.running_mean\n",
    "        module_output.running_var = module.running_var\n",
    "        module_output.num_batches_tracked = module.num_batches_tracked\n",
    "        if hasattr(module, \"qconfig\"):\n",
    "            module_output.qconfig = module.qconfig\n",
    "            \n",
    "    elif isinstance(module, Conv2dSame):\n",
    "        module_output = Conv3dSame(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.Conv2d):\n",
    "        module_output = torch.nn.Conv3d(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "            padding_mode=module.padding_mode\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.MaxPool2d):\n",
    "        module_output = torch.nn.MaxPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            dilation=module.dilation,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "    elif isinstance(module, torch.nn.AvgPool2d):\n",
    "        module_output = torch.nn.AvgPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module(\n",
    "            name, convert_3d(child)\n",
    "        )\n",
    "    del module\n",
    "\n",
    "    return module_output\n",
    "\n",
    "\n",
    "\n",
    "class TimmSegModel(nn.Module):\n",
    "    def __init__(self, backbone, segtype='unet', pretrained=False):\n",
    "        super(TimmSegModel, self).__init__()\n",
    "\n",
    "        self.encoder = timm4smp.models.create_model(\n",
    "            backbone,\n",
    "            in_chans=3,\n",
    "            features_only=True,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "\n",
    "        # num_input_channels = saved_model['encoder.bn1.running_mean'].shape[0]\n",
    "        # self.encoder.bn1 = nn.BatchNorm2d(num_features=64)\n",
    "        g = self.encoder(torch.rand(1, 3, 64, 64))\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.decoders.unet.model.UnetDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "            )\n",
    "        self.segmentation_head = nn.Conv2d(decoder_channels[n_blocks-1], 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        global_features = [0] + self.encoder(x)[:n_blocks]\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features\n",
    "    \n",
    "    \n",
    "class TimmModel(nn.Module):\n",
    "    def __init__(self, backbone, image_size, pretrained=False):\n",
    "        super(TimmModel, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=in_chans,\n",
    "            num_classes=1,\n",
    "            features_only=False,\n",
    "            drop_rate=0,\n",
    "            drop_path_rate=0,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "\n",
    "        if 'resnet' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif 'convnext' in backbone or 'nfnet' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "\n",
    "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=0, bidirectional=True, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "        self.lstm2 = nn.LSTM(hdim, 256, num_layers=2, dropout=0, bidirectional=True, batch_first=True)\n",
    "        self.head2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):  # (bs, nc*7, ch, sz, sz)\n",
    "        bs = x.shape[0]\n",
    "        x = x.view(bs * n_slice_per_c * 7, in_chans, self.image_size, self.image_size)\n",
    "        feat = self.encoder(x)\n",
    "        feat = feat.view(bs, n_slice_per_c * 7, -1)\n",
    "        feat1, _ = self.lstm(feat)\n",
    "        feat1 = feat1.contiguous().view(bs * n_slice_per_c * 7, 512)\n",
    "        feat2, _ = self.lstm2(feat)\n",
    "\n",
    "        return self.head(feat1), self.head2(feat2[:, 0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class Timm1BoneModel(nn.Module):\n",
    "    def __init__(self, backbone, image_size, pretrained=False):\n",
    "        super(Timm1BoneModel, self).__init__()\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=in_chans,\n",
    "            num_classes=1,\n",
    "            features_only=False,\n",
    "            drop_rate=0,\n",
    "            drop_path_rate=0,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "\n",
    "        if 'resnet' in backbone:\n",
    "            hdim = self.encoder.fc.out_features\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif 'convnext' in backbone or 'nfnet' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "\n",
    "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=0, bidirectional=True, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):  # (bs, nslice, ch, sz, sz)\n",
    "        bs = x.shape[0]\n",
    "        x = x.view(bs * n_slice_per_c, in_chans, self.image_size, self.image_size)\n",
    "        feat = self.encoder(x)\n",
    "        feat = feat.view(bs, n_slice_per_c, -1)\n",
    "        feat, _ = self.lstm(feat)\n",
    "        feat = feat.contiguous().view(bs * n_slice_per_c, -1)\n",
    "        feat = self.head(feat)\n",
    "        feat = feat.view(bs, n_slice_per_c).contiguous()\n",
    "\n",
    "        return feat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293b2c6-7f46-4c47-ba00-92f5e253d60a",
   "metadata": {},
   "source": [
    "<h2>Load Models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d960514-fdcb-489b-b9cc-4189d6e16f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_seg = []\n",
    "\n",
    "kernel_type = 'timm3d_v2s_unet4b_128_128_128_dsv2_flip12_shift333p7_gd1p5_mixup1_lr1e3_20x50ep'\n",
    "backbone = 'tf_efficientnetv2_s_in21ft1k'\n",
    "model_dir_seg = './seg_model'\n",
    "n_blocks = 4\n",
    "for fold in range(5):\n",
    "    model = TimmSegModel(backbone, pretrained=False)\n",
    "    model = convert_3d(model)\n",
    "    model = model.to(device)\n",
    "    load_model_file = os.path.join(model_dir_seg, f'{kernel_type}_fold{fold}_best.pth')\n",
    "    sd = torch.load(load_model_file)\n",
    "    if 'model_state_dict' in sd.keys():\n",
    "        sd = sd['model_state_dict']\n",
    "    sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "    # Assuming `model` is your PyTorch model\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     print(f\"Parameter name: {name}, Size: {param.size()}\")\n",
    "\n",
    "    model.load_state_dict(sd, strict=False)\n",
    "    model.eval()\n",
    "    models_seg.append(model)\n",
    "\n",
    "len(models_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1e0ca-7a8d-4035-ac0b-320c548331e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdf87694-d725-494c-aa65-5530d8c85527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_type = '0920_1bonev2_resnet18_224_15_6ch_augv2_mixupp5_drl3_rov1p2_bs8_lr23e5_eta23e6_50ep'\n",
    "model_dir_cls = './models'\n",
    "backbone = 'resnet18'\n",
    "in_chans = 6\n",
    "models_cls1 = []\n",
    "\n",
    "for fold in range(5):\n",
    "    model = Timm1BoneModel(backbone, image_size=224, pretrained=False)\n",
    "    load_model_file = os.path.join(model_dir_cls, f'{kernel_type}_fold{fold}_best.pth')\n",
    "    sd = torch.load(load_model_file, map_location='cpu')\n",
    "    if 'model_state_dict' in sd.keys():\n",
    "        sd = sd['model_state_dict']\n",
    "    sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "    model.load_state_dict(sd, strict=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    models_cls1.append(model)\n",
    "\n",
    "len(models_cls1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1a3cf89-dea6-433b-a27c-b34feb8c0825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_type = '0920_2d_lstmv22headv2_convnn_224_15_6ch_8flip_augv2_drl3_rov1p2_rov3p2_bs4_lr6e5_eta6e6_lw151_50ep'\n",
    "model_dir_cls = './conv_model'\n",
    "backbone = 'convnext_nano'\n",
    "in_chans = 6\n",
    "models_cls2 = []\n",
    "\n",
    "for fold in range(5):\n",
    "    model = TimmModel(backbone, image_size=224, pretrained=False)\n",
    "    model = model.to(device)\n",
    "    load_model_file = os.path.join(model_dir_cls, f'{kernel_type}_fold{fold}_best.pth')\n",
    "    sd = torch.load(load_model_file)\n",
    "    if 'model_state_dict' in sd.keys():\n",
    "        sd = sd['model_state_dict']\n",
    "    sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "    model.load_state_dict(sd, strict=True)\n",
    "    model.eval()\n",
    "    models_cls2.append(model)\n",
    "\n",
    "len(models_cls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91bd6782-a7d9-4f9a-91d3-aa9f8b0bf485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 10 21:18:50 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A16          On   | 00000000:E6:00.0 Off |                    0 |\n",
      "|  0%   45C    P0    27W /  62W |   1612MiB / 15356MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "266997af-3f6d-4246-b6c6-14d6e605ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bone(msk, cid, t_paths, cropped_images):\n",
    "    n_scans = len(t_paths)\n",
    "    bone = []\n",
    "    try:\n",
    "        msk_b = msk[cid] > 0.2\n",
    "        msk_c = msk[cid] > 0.05\n",
    "\n",
    "        x = np.where(msk_b.sum(1).sum(1) > 0)[0]\n",
    "        y = np.where(msk_b.sum(0).sum(1) > 0)[0]\n",
    "        z = np.where(msk_b.sum(0).sum(0) > 0)[0]\n",
    "\n",
    "        if len(x) == 0 or len(y) == 0 or len(z) == 0:\n",
    "            x = np.where(msk_c.sum(1).sum(1) > 0)[0]\n",
    "            y = np.where(msk_c.sum(0).sum(1) > 0)[0]\n",
    "            z = np.where(msk_c.sum(0).sum(0) > 0)[0]\n",
    "\n",
    "        x1, x2 = max(0, x[0] - 1), min(msk.shape[1], x[-1] + 1)\n",
    "        y1, y2 = max(0, y[0] - 1), min(msk.shape[2], y[-1] + 1)\n",
    "        z1, z2 = max(0, z[0] - 1), min(msk.shape[3], z[-1] + 1)\n",
    "        zz1, zz2 = int(z1 / msk_size * n_scans), int(z2 / msk_size * n_scans)\n",
    "\n",
    "        inds = np.linspace(zz1 ,zz2-1 ,n_slice_per_c).astype(int)\n",
    "        inds_ = np.linspace(z1 ,z2-1 ,n_slice_per_c).astype(int)\n",
    "        for sid, (ind, ind_) in enumerate(zip(inds, inds_)):\n",
    "\n",
    "            msk_this = msk[cid, :, :, ind_]\n",
    "\n",
    "            images = []\n",
    "            for i in range(-n_ch//2+1, n_ch//2+1):\n",
    "                try:\n",
    "                    dicom = pydicom.read_file(t_paths[ind+i])\n",
    "                    images.append(dicom.pixel_array)\n",
    "                except:\n",
    "                    images.append(np.zeros((512, 512)))\n",
    "\n",
    "            data = np.stack(images, -1)\n",
    "            data = data - np.min(data)\n",
    "            data = data / (np.max(data) + 1e-4)\n",
    "            data = (data * 255).astype(np.uint8)\n",
    "            msk_this = msk_this[x1:x2, y1:y2]\n",
    "            xx1 = int(x1 / msk_size * data.shape[0])\n",
    "            xx2 = int(x2 / msk_size * data.shape[0])\n",
    "            yy1 = int(y1 / msk_size * data.shape[1])\n",
    "            yy2 = int(y2 / msk_size * data.shape[1])\n",
    "            data = data[xx1:xx2, yy1:yy2]\n",
    "            data = np.stack([cv2.resize(data[:, :, i], (image_size_cls, image_size_cls), interpolation = cv2.INTER_LINEAR) for i in range(n_ch)], -1)\n",
    "            msk_this = (msk_this * 255).astype(np.uint8)\n",
    "            msk_this = cv2.resize(msk_this, (image_size_cls, image_size_cls), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "            data = np.concatenate([data, msk_this[:, :, np.newaxis]], -1)\n",
    "\n",
    "            bone.append(torch.tensor(data))\n",
    "\n",
    "    except:\n",
    "        for sid in range(n_slice_per_c):\n",
    "            bone.append(torch.ones((image_size_cls, image_size_cls, n_ch+1)).int())\n",
    "\n",
    "    cropped_images[cid] = torch.stack(bone, 0)\n",
    "\n",
    "\n",
    "def load_cropped_images(msk, image_folder, n_ch=n_ch):\n",
    "\n",
    "    t_paths = sorted(glob(os.path.join(image_folder, \"*\")), key=lambda x: int(x.split('/')[-1].split(\".\")[0]))\n",
    "    for cid in range(7):\n",
    "        threads[cid] = threading.Thread(target=load_bone, args=(msk, cid, t_paths, cropped_images))\n",
    "        threads[cid].start()\n",
    "    for cid in range(7):\n",
    "        threads[cid].join()\n",
    "\n",
    "    return torch.cat(cropped_images, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa563b-78a0-4969-a0cb-6efe2e879e86",
   "metadata": {},
   "source": [
    "<h2>Predict</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19c1df18-fc88-4d8c-a532-40c42f69b06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 3/3 [00:40<00:00, 13.52s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs1 = []\n",
    "outputs2 = []\n",
    "\n",
    "bar = tqdm(loader_seg)\n",
    "with torch.no_grad():\n",
    "    for batch_id, (images) in enumerate(bar):\n",
    "        images = images.cuda()\n",
    "\n",
    "        # SEG\n",
    "        pred_masks = []\n",
    "        for model in models_seg:\n",
    "            pmask = model(images).sigmoid()\n",
    "            pred_masks.append(pmask)\n",
    "        pred_masks = torch.stack(pred_masks, 0).mean(0).cpu().numpy()\n",
    "\n",
    "        # Build cls input\n",
    "        cls_inp = []\n",
    "        threads = [None] * 7\n",
    "        cropped_images = [None] * 7\n",
    "\n",
    "        for i in range(pred_masks.shape[0]):\n",
    "            row = df.iloc[batch_id*batch_size_seg+i]\n",
    "            cropped_images = load_cropped_images(pred_masks[i], row.image_folder)\n",
    "            cls_inp.append(cropped_images.permute(0, 3, 1, 2).float() / 255.)\n",
    "        cls_inp = torch.stack(cls_inp, 0).to(device)  # (1, 105, 6, 224, 224)\n",
    "\n",
    "        pred_cls1, pred_cls2 = [], []\n",
    "        # CLS 2\n",
    "        for _, model in enumerate(models_cls2):\n",
    "            logits, logits2 = model(cls_inp)\n",
    "            pred_cls1.append(logits.sigmoid().view(-1, 7, n_slice_per_c))\n",
    "            pred_cls2.append(logits2.sigmoid())\n",
    "\n",
    "        # CLS 1\n",
    "        cls_inp = cls_inp.view(7, 15, 6, image_size_cls, image_size_cls).contiguous()\n",
    "        for _, model in enumerate(models_cls1):\n",
    "            logits = model(cls_inp)\n",
    "            pred_cls1.append(logits.sigmoid().view(-1, 7, n_slice_per_c))\n",
    "\n",
    "        pred_cls1 = torch.stack(pred_cls1, 0).mean(0)\n",
    "        pred_cls2 = torch.stack(pred_cls2, 0).mean(0)\n",
    "        outputs1.append(pred_cls1.cpu())\n",
    "        outputs2.append(pred_cls2.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b5d2c-fa95-4c98-a9d0-fa37406b7ee3",
   "metadata": {},
   "source": [
    "<h2>Outputs</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4a88052-a12d-4d52-855a-a4261a298b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs1 = torch.cat(outputs1)\n",
    "outputs2 = torch.cat(outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef86c619-a505-446f-b13e-97786678b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED1 = (outputs1.mean(-1)).clamp(0.0001, 0.9999)\n",
    "PRED2 = (outputs2.view(-1)).clamp(0.0001, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac219fac-dbe7-4352-81c2-2b32cb6b5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ids = []\n",
    "for _, row in df.iterrows():\n",
    "    for i in range(7):\n",
    "        row_ids.append(row.StudyInstanceUID + f'_C{i+1}')\n",
    "    row_ids.append(row.StudyInstanceUID + '_patient_overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c28c4c0-e7db-4b14-8b79-956bb573db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame({\n",
    "    'row_id': row_ids,\n",
    "    'fractured': torch.cat([PRED1, PRED2.unsqueeze(1)], 1).view(-1),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abfcf21a-d1ef-468c-a8f3-afdf790e187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submissionresnet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccaa0867-ddc0-4aba-b3d7-69bafb5f12b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>fractured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C1</td>\n",
       "      <td>0.033526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C2</td>\n",
       "      <td>0.050589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C3</td>\n",
       "      <td>0.017206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C4</td>\n",
       "      <td>0.026012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C5</td>\n",
       "      <td>0.057979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C6</td>\n",
       "      <td>0.268392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C7</td>\n",
       "      <td>0.441880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_patient_overall</td>\n",
       "      <td>0.403687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C1</td>\n",
       "      <td>0.016853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C2</td>\n",
       "      <td>0.034683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C3</td>\n",
       "      <td>0.033408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C4</td>\n",
       "      <td>0.049175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C5</td>\n",
       "      <td>0.043538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C6</td>\n",
       "      <td>0.062341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C7</td>\n",
       "      <td>0.120163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_patient_overall</td>\n",
       "      <td>0.113701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C1</td>\n",
       "      <td>0.021906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C2</td>\n",
       "      <td>0.250863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C3</td>\n",
       "      <td>0.040769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C4</td>\n",
       "      <td>0.092129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C5</td>\n",
       "      <td>0.123581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C6</td>\n",
       "      <td>0.149740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C7</td>\n",
       "      <td>0.200967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_patient_overall</td>\n",
       "      <td>0.443938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       row_id  fractured\n",
       "0                1.2.826.0.1.3680043.22327_C1   0.033526\n",
       "1                1.2.826.0.1.3680043.22327_C2   0.050589\n",
       "2                1.2.826.0.1.3680043.22327_C3   0.017206\n",
       "3                1.2.826.0.1.3680043.22327_C4   0.026012\n",
       "4                1.2.826.0.1.3680043.22327_C5   0.057979\n",
       "5                1.2.826.0.1.3680043.22327_C6   0.268392\n",
       "6                1.2.826.0.1.3680043.22327_C7   0.441880\n",
       "7   1.2.826.0.1.3680043.22327_patient_overall   0.403687\n",
       "8                1.2.826.0.1.3680043.25399_C1   0.016853\n",
       "9                1.2.826.0.1.3680043.25399_C2   0.034683\n",
       "10               1.2.826.0.1.3680043.25399_C3   0.033408\n",
       "11               1.2.826.0.1.3680043.25399_C4   0.049175\n",
       "12               1.2.826.0.1.3680043.25399_C5   0.043538\n",
       "13               1.2.826.0.1.3680043.25399_C6   0.062341\n",
       "14               1.2.826.0.1.3680043.25399_C7   0.120163\n",
       "15  1.2.826.0.1.3680043.25399_patient_overall   0.113701\n",
       "16                1.2.826.0.1.3680043.5876_C1   0.021906\n",
       "17                1.2.826.0.1.3680043.5876_C2   0.250863\n",
       "18                1.2.826.0.1.3680043.5876_C3   0.040769\n",
       "19                1.2.826.0.1.3680043.5876_C4   0.092129\n",
       "20                1.2.826.0.1.3680043.5876_C5   0.123581\n",
       "21                1.2.826.0.1.3680043.5876_C6   0.149740\n",
       "22                1.2.826.0.1.3680043.5876_C7   0.200967\n",
       "23   1.2.826.0.1.3680043.5876_patient_overall   0.443938"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b20d748-ed00-491d-ba04-40c676a26e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
